{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Litics360 Prototype Version Pv1.0\n",
    "# Data Collection\n",
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# Voter Data - Ohio Secretary of State Voter Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background on the data source:\n",
    "The database that will be utilized for building the prototype version 1.0 of Litics360 is a record collection of registered voters in the state of Ohio, as submitted by each county Board of Elections. This website is Ohio State of Secretary's official voter database. These records are submitted and maintained in accordance with the Ohio Revised Code. Current files include voting histories for elections from year 2000 to present as provided by the counties.\n",
    "\n",
    "Source link: https://www6.ohiosos.gov/ords/f?p=VOTERFTP:STWD:::#stwdVtrFiles\n",
    "\n",
    "### Purpose behind usage of database:\n",
    "This dataset will serve as the foundation of voter data for predictive prototyping as it contains reliable and publically available voter information of Ohio's voter records, including voter's demogragraphic information, registered party affiliation and turnout in elections (Primary/General) since the 2000s.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## 1. Download Voter Dataset\n",
    "### Brief scope of tasks:\n",
    "    1.1 Import necessary libraries\n",
    "    1.2 Initalize download function\n",
    "    1.3 Extract appropriate links from Ohio SOS statewide voter files download page\n",
    "    1.4 Download and decompress files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "1.1 Importing necessary libraries ...\n",
      "Import --> COMPLETED\n",
      "\n",
      "----------------------------------------\n",
      "1.2 Initalized download function\n",
      "\n",
      "----------------------------------------\n",
      "1.3 Extracting appropriate links from Ohio SOS statewide voter files download page ...\n",
      "\n",
      "---- Source:\n",
      " https://www6.ohiosos.gov/ords/f?p=VOTERFTP:STWD:::#stwdVtrFiles \n",
      "\n",
      "---- Links extracted:\n",
      " ['https://www6.ohiosos.gov/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:363', 'https://www6.ohiosos.gov/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:364', 'https://www6.ohiosos.gov/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:365', 'https://www6.ohiosos.gov/ords/f?p=VOTERFTP:DOWNLOAD::FILE:NO:2:P2_PRODUCT_NUMBER:366']\n",
      "\n",
      "---- Files in directory:\n",
      " ['Blind', '.DS_Store', 'Model']\n",
      "\n",
      "\n",
      "Extract links --> COMPLETED\n",
      "\n",
      "----------------------------------------\n",
      "1.4 Downloading and decompressing files ...\n",
      "\n",
      "\n",
      " Downloading -->  VoterData/voterfile1.txt.gz\n",
      "[██████████████████████████████████████████████████]\n",
      "Download --> COMPLETED\n",
      "\n",
      "Decompressing -->  VoterData/voterfile1.txt\n",
      "Decompress --> COMPLETED\n",
      "\n",
      " Downloading -->  VoterData/voterfile2.txt.gz\n",
      "[██████████████████████████████████████████████████]\n",
      "Download --> COMPLETED\n",
      "\n",
      "Decompressing -->  VoterData/voterfile2.txt\n",
      "Decompress --> COMPLETED\n",
      "\n",
      " Downloading -->  VoterData/voterfile3.txt.gz\n",
      "[██████████████████████████████████████████████████]\n",
      "Download --> COMPLETED\n",
      "\n",
      "Decompressing -->  VoterData/voterfile3.txt\n",
      "Decompress --> COMPLETED\n",
      "\n",
      " Downloading -->  VoterData/voterfile4.txt.gz\n",
      "[██████████████████████████████████████████████████]\n",
      "Download --> COMPLETED\n",
      "\n",
      "Decompressing -->  VoterData/voterfile4.txt\n",
      "Decompress --> COMPLETED\n",
      "\n",
      "---- Files in directory:\n",
      " ['Blind', '.DS_Store', 'Model', 'voterfile4.txt', 'voterfile2.txt', 'voterfile3.txt', 'voterfile1.txt']\n",
      "\n",
      "\n",
      "File download/decompress --> COMPLETED\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "    #1.1 Import necessary libraries\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('\\n----------------------------------------\\n1.1 Importing necessary libraries ...')\n",
    "#For html page import and to find links\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sys\n",
    "import requests\n",
    "import shutil, os\n",
    "import send2trash\n",
    "\n",
    "#For descompressing gzip files\n",
    "import gzip\n",
    "import shutil\n",
    "print('Import --> COMPLETED')\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    #1.2 Initalize download function\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('\\n----------------------------------------\\n1.2 Initalized download function')\n",
    "\n",
    "def download(url, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        print('\\n','Downloading --> ',filename)\n",
    "        response = requests.get(url, stream=True)\n",
    "        total = response.headers.get('content-length')\n",
    "\n",
    "        if total is None:\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            downloaded = 0\n",
    "            total = int(total)\n",
    "            for data in response.iter_content(chunk_size=max(int(total / 1000), 1024 * 1024)):\n",
    "                downloaded += len(data)\n",
    "                f.write(data)\n",
    "                done = int(50 * downloaded / total)\n",
    "                sys.stdout.write('\\r[{}{}]'.format('█' * done, '.' * (50 - done)))\n",
    "                sys.stdout.flush()\n",
    "    sys.stdout.write('\\nDownload --> COMPLETED\\n')\n",
    "    \n",
    "#------------------------------------------------------------------------------------------\n",
    "    #1.3 Extract appropriate links from Ohio SOS statewide voter files download page\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('\\n----------------------------------------\\n1.3 Extracting appropriate links from Ohio SOS statewide voter files download page ...')\n",
    "#URL to SOS Ohio statewide voter files page\n",
    "main_url = \"https://www6.ohiosos.gov/ords/f?p=VOTERFTP:STWD:::#stwdVtrFiles\"\n",
    "\n",
    "#Scrape from the SOS Ohio statewide voter files page\n",
    "response = requests.get(main_url)\n",
    "page = BeautifulSoup(response.content, \"html5lib\")\n",
    "\n",
    "link_leader = 'https://www6.ohiosos.gov/ords/'\n",
    "links = []\n",
    "\n",
    "#Get the links for statewide download files\n",
    "for link in page.findAll('a', attrs={'href': re.compile('f?p=VOTERFTP:DOWNLOAD::FILE:')}):\n",
    "    links.append(link_leader + str(link.get('href')))\n",
    "    \n",
    "#Display extracted links\n",
    "print('\\n---- Source:\\n',main_url,\n",
    "      '\\n\\n---- Links extracted:\\n',list(links))\n",
    "\n",
    "#Path directory text\n",
    "path = 'VoterData/'\n",
    "      \n",
    "# Display files in directory before downloading\n",
    "dir_list = os.listdir(path)  \n",
    "print('\\n---- Files in directory:\\n', dir_list)\n",
    "\n",
    "#Create filenames for easy download\n",
    "gz_files =[]\n",
    "txt_files = []\n",
    "for i in range(1,5):\n",
    "    gz_files.append('VoterData/voterfile'+str(i)+'.txt.gz')\n",
    "    txt_files.append('VoterData/voterfile'+str(i)+'.txt')\n",
    "gz_files.sort()\n",
    "txt_files.sort()\n",
    "\n",
    "print('\\n\\nExtract links --> COMPLETED')\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    #1.4 Download and decompress files\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('\\n----------------------------------------\\n1.4 Downloading and decompressing files ...\\n')\n",
    "for i in range(0,4):\n",
    "    \n",
    "    #Download files\n",
    "    download(links[i],gz_files[i])\n",
    "    \n",
    "    #Decompress files\n",
    "    print('\\nDecompressing --> ',txt_files[i])\n",
    "    \n",
    "    with gzip.open((gz_files[i]), 'rb') as f_in:\n",
    "        with open((txt_files[i]), 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "    print('Decompress --> COMPLETED')\n",
    "\n",
    "# Sending gzip files to trash\n",
    "send2trash.send2trash('VoterData/voterfile1.txt.gz')\n",
    "send2trash.send2trash('VoterData/voterfile2.txt.gz')\n",
    "send2trash.send2trash('VoterData/voterfile3.txt.gz')\n",
    "send2trash.send2trash('VoterData/voterfile4.txt.gz')\n",
    "\n",
    "dir_list = os.listdir(path)  \n",
    "print('\\n---- Files in directory:\\n', dir_list)\n",
    "\n",
    "print('\\n\\nFile download/decompress --> COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## 2. Combine Voter Data\n",
    "\n",
    "### Brief scope of tasks:\n",
    "    2.1 Import necessary libraries\n",
    "    2.2 Import and combine files into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "2.1 Importing necessary libraries ...\n",
      "Import --> COMPLETED\n",
      "\n",
      "--------------------------------\n",
      "2.2 Importing and merging all data files ...\n",
      "Import file#1 --> COMPLETED\n",
      "Import file#2 --> COMPLETED\n",
      "Import file#3 --> COMPLETED\n",
      "Import file#4--> COMPLETED\n",
      "\n",
      "Merging data files ...\n",
      "Merge --> COMPLETED\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "    #2.1 Import necessary libraries\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('\\n--------------------------------\\n2.1 Importing necessary libraries ...')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('Import --> COMPLETED')\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    #2.2 Import and combine files into one dataset\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\n--------------------------------\\n2.2 Importing and merging all data files ...')\n",
    "\n",
    "\n",
    "voterdata_file1 = pd.read_csv('VoterData/voterfile1.txt',sep=\",\", quotechar='\"',header=0, encoding='ISO-8859-1',na_values=['NA'],low_memory=False)\n",
    "print('Import file#1 --> COMPLETED')\n",
    "voterdata_file2 = pd.read_csv('VoterData/voterfile2.txt',sep=\",\", quotechar='\"',header=0, encoding='ISO-8859-1',na_values=['NA'],low_memory=False)\n",
    "print('Import file#2 --> COMPLETED')\n",
    "voterdata_file3 = pd.read_csv('VoterData/voterfile3.txt',sep=\",\", quotechar='\"',header=0, encoding='ISO-8859-1',na_values=['NA'],low_memory=False)\n",
    "print('Import file#3 --> COMPLETED')\n",
    "voterdata_file4 = pd.read_csv('VoterData/voterfile4.txt',sep=\",\", quotechar='\"',header=0, encoding='ISO-8859-1',na_values=['NA'],low_memory=False)\n",
    "print('Import file#4--> COMPLETED')\n",
    "\n",
    "#Combine all into one dataframe\n",
    "print('\\nMerging data files ...')\n",
    "df = pd.concat([voterdata_file1,voterdata_file2,voterdata_file3,voterdata_file4], \n",
    "                         axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "                         keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
    "print('Merge --> COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## 3. Organize and prep dataset\n",
    "\n",
    "### Brief scope of tasks:\n",
    "    3.1:  Import necessary libraries\n",
    "    3.2:  Preview dataset information\n",
    "    3.3:  Dropping voters missing key values\n",
    "    3.4:  Feature --> CPVI (Cook Partisan Voting Index) of Reps ---- CD_REP_CPVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "3.1 Importing necessary libraries ...\n",
      "Import --> COMPLETED\n",
      "\n",
      "--------------------------------\n",
      "3.2 Previewing dataset information ...\n",
      "\n",
      "# of Registered Voters:  7772371\n",
      "\n",
      "# of Features:  109\n",
      "\n",
      "Party Affiliations Listed Types:  ['R' nan 'D' 'G' 'L']\n",
      "--> nan = Undeclared\n",
      "--> D = Democrat\n",
      "--> R = Republican\n",
      "--> G = Green\n",
      "--> L = Libertarian\n",
      "\n",
      "# of Undeclared Party Affiliation:  4565332\n",
      "# of Declared Party Affiliation:  3207039\n",
      "\n",
      "---> END OF PREVIEW <---\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "3.3  Dropping voters missing key values...\n",
      "\n",
      "\t3.3.1  Drop voters missing SOS_VOTERID value --> COMPLETED\n",
      "\n",
      "\t3.3.2  Drop voters missing CONGRESSIONAL_DISTRICT value --> COMPLETED\n",
      "\n",
      "\t3.3.3  Drop voters missing COUNTY_NUMBER value --> COMPLETED\n",
      "\n",
      "---Original # of rows: 7772371 \n",
      "---Current # of rows: 7771790\n",
      "\n",
      "---Original # of columns: 109 \n",
      "---Current # of columns: 109\n",
      "\n",
      "Clean --> COMPLETED\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "    #3.1 Import necessary libraries\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('\\n--------------------------------\\n3.1 Importing necessary libraries ...')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('Import --> COMPLETED')\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    #3.2: Preview dataset information\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "#Preview changes -- Compare original #rows to current #rows\n",
    "print('\\n--------------------------------\\n3.2 Previewing dataset information ...')\n",
    "\n",
    "#Current row count\n",
    "row_ct1 = df.shape[0]\n",
    "#Current col count\n",
    "col_ct1 = df.shape[1]\n",
    "\n",
    "#Number of rows, columns\n",
    "print (\"\\n# of Registered Voters: \", row_ct1)\n",
    "print (\"\\n# of Features: \", col_ct1)\n",
    "\n",
    "#Unique types of party affiliations listed in dataset\n",
    "parties = df.PARTY_AFFILIATION.unique()\n",
    "print(\"\\nParty Affiliations Listed Types: \", parties)\n",
    "print(\"--> nan = Undeclared\\n--> D = Democrat\\n--> R = Republican\\n--> G = Green\\n--> L = Libertarian\")\n",
    "\n",
    "#Number of undeclared/declared voters\n",
    "num_undeclaredvoters = sum(pd.isna(df['PARTY_AFFILIATION']))\n",
    "print(\"\\n# of Undeclared Party Affiliation: \", num_undeclaredvoters)\n",
    "\n",
    "num_declaredvoters = len(df)-(sum(pd.isna(df['PARTY_AFFILIATION'])))\n",
    "print(\"# of Declared Party Affiliation: \", num_declaredvoters)\n",
    "\n",
    "print('\\n---> END OF PREVIEW <---\\n')\n",
    "\n",
    "#------------------------------------------------------------------------------------------  \n",
    "    #3.3: Dropping voters missing key values\n",
    "#------------------------------------------------------------------------------------------  \n",
    "\n",
    "print('\\n--------------------------------\\n3.3  Dropping voters missing key values...')\n",
    "\n",
    "#3.3.1: Drop rows with missing SOS_VOTERID value\n",
    "df = df[pd.notnull(df['SOS_VOTERID'])]\n",
    "print('\\n\\t3.3.1  Drop voters missing SOS_VOTERID value --> COMPLETED')\n",
    "\n",
    "#3.3.2: Drop rows with missing CONGRESSIONAL_DISTRICT value\n",
    "df = df[pd.notnull(df['CONGRESSIONAL_DISTRICT'])]\n",
    "#Convert CONGRESSIONAL_DISTRICT from float to int\n",
    "df[\"CONGRESSIONAL_DISTRICT\"]= df[\"CONGRESSIONAL_DISTRICT\"].astype(int) \n",
    "print('\\n\\t3.3.2  Drop voters missing CONGRESSIONAL_DISTRICT value --> COMPLETED')\n",
    "\n",
    "#3.3.3: Drop rows with missing COUNTY_NUMBER value\n",
    "df = df[pd.notnull(df['COUNTY_NUMBER'])]\n",
    "#Convert COUNTY_NUMBER from float to int\n",
    "df[\"COUNTY_NUMBER\"]= df[\"COUNTY_NUMBER\"].astype(int) \n",
    "print('\\n\\t3.3.3  Drop voters missing COUNTY_NUMBER value --> COMPLETED')\n",
    "\n",
    "#Preview changes -- Compare original #rows to current #rows\n",
    "#Current row count\n",
    "row_ct2 = df.shape[0]\n",
    "print(\"\\n---Original # of rows:\", row_ct1,\n",
    "      \"\\n---Current # of rows:\", row_ct2)\n",
    "\n",
    "#Current col count\n",
    "col_ct2 = df.shape[1]\n",
    "#Preview changes -- Compare original #columns to current #columns\n",
    "print(\"\\n---Original # of columns:\", col_ct1,\n",
    "      \"\\n---Current # of columns:\", col_ct2)\n",
    "print('\\nClean --> COMPLETED')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## 4. Import Congressional District Representatives (Party Affiliation & CPVI)\n",
    "\n",
    "### Brief scope of tasks:\n",
    "    4.1:  Import necessary libraries\n",
    "    4.2:  Feature --> Party Affiliation of Reps ---- CD_REP_PARTY\n",
    "    4.3:  Feature --> CPVI (Cook Partisan Voting Index) of Reps ---- CD_REP_CPVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "4.1 Importing necessary libraries ...\n",
      "Import --> COMPLETED\n",
      "\n",
      "--------------------------------\n",
      "4.2 Feature --> Party Affiliation of Reps ---- CD_REP_PARTY ...\n",
      "Preview feature CD_REP_PARTY:\n",
      " 0    15\n",
      "1    15\n",
      "Name: CONGRESSIONAL_DISTRICT, dtype: int64\n",
      "\n",
      "Feature CD_REP_PARTY --> COMPLETED\n",
      "\n",
      "--------------------------------\n",
      "4.3 Engineering feature --> CPVI of Reps ---- CD_REP_CPVI ...\n",
      "Preview feature CD_REP_CPVI:\n",
      "    CD_REP_CPVI\n",
      "0            7\n",
      "1            7\n",
      "\n",
      "Feature CD_REP_CPVI --> COMPLETED\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "    #4.1 Import necessary libraries\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\n--------------------------------\\n4.1 Importing necessary libraries ...')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.html import read_html\n",
    "print('Import --> COMPLETED')\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    #4.2: Feature --> Party Affiliation of Reps ---- CD_REP_PARTY\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\n--------------------------------\\n4.2 Feature --> Party Affiliation of Reps ---- CD_REP_PARTY ...')\n",
    "#Pull in Congressional District Representatives for all states from official page\n",
    "\n",
    "page_reps = 'https://www.house.gov/representatives'\n",
    "\n",
    "#Pull in all tables containing House of Reps info\n",
    "table_reps = pd.read_html(page_reps,attrs={'class':'table'})\n",
    "\n",
    "#--FYI--Ohio district is the 38th table\n",
    "#Pull in 38th table and get rid of the unnecessary columns\n",
    "ohio_reps = table_reps[38].drop(axis=1, labels=['Phone', 'Office Room', 'Committee Assignment'])\n",
    "\n",
    "#Clean OHIO_REPS dataframe\n",
    "    #1. Extract only district numbers -- get rid of st/rd/th\n",
    "    #2. Convert district number into numeric values\n",
    "    #3. Drop all cols except district, name, party\n",
    "    #4. Rename District to CONGRESSIONAL_DISTRICT, party to CD_REP_PARTY, name to CD_REP_NAME\n",
    "    #5. Merge with df\n",
    "\n",
    "#Iterate over each row\n",
    "for index_label, row_series in ohio_reps.iterrows():\n",
    "\n",
    "    # For each row update the 'District' value -- by removing the last two chracters\n",
    "    ohio_reps.at[index_label , 'District'] = row_series['District'][:len(row_series['District'])-2]\n",
    "\n",
    "#Turn all values for District and CONGRESSIONAL_DISTRICT col to INT\n",
    "ohio_reps['District'] = ohio_reps['District'].astype(int)\n",
    "\n",
    "#Rename District to CONGRESSIONAL_DISTRICT, party to CONGRESSIONAL_DISTRICT_REP_PARTY\n",
    "ohio_reps.rename(columns={'District':'CONGRESSIONAL_DISTRICT',\n",
    "                          'Party':'CD_REP_PARTY',\n",
    "                          'Name': 'CD_REP_NAME'\n",
    "                         }, \n",
    "                 inplace=True)\n",
    "\n",
    "#Merge with main df -- match to CONGRESSIONAL_DISTRICT\n",
    "df = pd.merge(df, ohio_reps, on='CONGRESSIONAL_DISTRICT')\n",
    "\n",
    "#Preview changes -- first two rows of CD_REP_PARTY\n",
    "print('Preview feature CD_REP_PARTY:\\n',df['CONGRESSIONAL_DISTRICT'].head(2))\n",
    "print('\\nFeature CD_REP_PARTY --> COMPLETED')\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    #4.3:  Feature --> CPVI (Cook Partisan Voting Index) of Reps ---- CD_REP_CPVI\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\n--------------------------------\\n4.3 Engineering feature --> CPVI of Reps ---- CD_REP_CPVI ...')\n",
    "#Pull in Congressional District Representatives for Ohio from Wiki\n",
    "page_CPVI = 'https://en.wikipedia.org/wiki/United_States_congressional_delegations_from_Ohio'\n",
    "\n",
    "#Pull in all tables\n",
    "table_CPVI = pd.read_html(page_CPVI,attrs={'class':'wikitable'})\n",
    "\n",
    "reps_CPVI = pd.DataFrame(table_CPVI[0])\n",
    "\n",
    "reps_CPVI = reps_CPVI.drop(axis=1, labels=['Representative(Residence)', 'Party', 'Incumbency', 'District map'])\n",
    "\n",
    "#Clean table_CPVI dataframe\n",
    "    #1. Rename district values to only numeric-- get rid of st/rd/th\n",
    "    #2. Turn district from STR to INT\n",
    "    #3. Drop all cols except district and cpvi\n",
    "    #4. Rename District to CONGRESSIONAL_DISTRICT, CPVI to CD_REP\n",
    "    #5. Merge with df\n",
    "\n",
    "#Iterate over each row\n",
    "for index_label, row_series in reps_CPVI.iterrows():\n",
    "\n",
    "    # For each row update the 'District' value -- by removing the last two chracters\n",
    "    reps_CPVI.at[index_label , 'District'] = row_series['District'][:len(row_series['District'])-2]\n",
    "    reps_CPVI.at[index_label , 'CPVI'] = row_series['CPVI'][2:len(row_series['CPVI'])]\n",
    "    \n",
    "#Turn all values for District and CONGRESSIONAL_DISTRICT col to INT\n",
    "reps_CPVI['District'] = reps_CPVI['District'].astype(int)\n",
    "reps_CPVI['CPVI'] = reps_CPVI['CPVI'].astype(int)\n",
    "\n",
    "#Rename District to CONGRESSIONAL_DISTRICT, CPVI to CD_REP_CPVI\n",
    "reps_CPVI.rename(columns={'District':'CONGRESSIONAL_DISTRICT',\n",
    "                        'CPVI':'CD_REP_CPVI'},\n",
    "               inplace=True)\n",
    "\n",
    "#Merge with main df -- match to CONGRESSIONAL_DISTRICT\n",
    "df = pd.merge(df, reps_CPVI, on='CONGRESSIONAL_DISTRICT')\n",
    "\n",
    "print('Preview feature CD_REP_CPVI:\\n',df.iloc[:2,-1:])\n",
    "print('\\nFeature CD_REP_CPVI --> COMPLETED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## 5. Partition data\n",
    "\n",
    "### Brief scope of tasks:\n",
    "    5.1:  Import necessary libraries\n",
    "    5.2:  Partition: Blind Data and Model Data (10/90)\n",
    "    5.3:  Export partitioned files into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "5.1 Importing necessary libraries ...\n",
      "Import --> COMPLETED\n",
      "\n",
      "--------------------------------\n",
      "5.2 Creating partition: Blind Data and Model Data (10/90) ...\n",
      "\n",
      "10% of 7771790 = 777179 \n",
      " BLIND dataset = 777179\n",
      "\n",
      "90% of 7771790 = 6994611 \n",
      " MODEL dataset = 6994611\n",
      "\n",
      "\n",
      "Parition --> COMPLETED\n",
      "\n",
      "--------------------------------\n",
      "5.3 Exporting and saving partitioned data files\n",
      "Creating file: model_voterdata.csv --> COMPLETED\n",
      "Creating file: blind_voterdata.csv --> COMPLETED\n",
      "Sending GZip files to local trash folder --> COMPLETED\n",
      "\n",
      "---- Files in directory:\n",
      " ['Blind', '.DS_Store', 'Model']\n",
      "\n",
      "\n",
      "Export & Save --> COMPLETED\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "    #5.1 Import necessary libraries\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\n--------------------------------\\n5.1 Importing necessary libraries ...')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "import shutil, os\n",
    "import send2trash\n",
    "print('Import --> COMPLETED')\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    #5.2 Partition: Blind Data and Model Data (10/90)\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\n--------------------------------\\n5.2 Creating partition: Blind Data and Model Data (10/90) ...')\n",
    "#Partition into blind and model - 10/90, random_state none, shuffle True, \n",
    "model_df, blind_df= split(\n",
    "    df, train_size=0.9, test_size=0.1, random_state=None, shuffle=True)\n",
    "\n",
    "#Calculate percentage, check # of rows in BLIND_TESTING df\n",
    "print(\"\\n10% of\", len(df) ,\"=\",round(0.1*(len(df))),\"\\n BLIND dataset =\",len(blind_df))\n",
    "\n",
    "#Calculate percentage, check # of rows in MODEL df\n",
    "print(\"\\n90% of\", len(df) ,\"=\",round(0.9*(len(df))),\"\\n MODEL dataset =\",len(model_df))\n",
    "print('\\n\\nParition --> COMPLETED')\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    #5.3 Export partitioned files into folders\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "print('\\n--------------------------------\\n5.3 Exporting and saving partitioned data files')\n",
    "\n",
    "#Function for easy export to csv\n",
    "def df2csv(df,filename):\n",
    "    path = 'VoterData/'+filename+'_voterdata.csv'\n",
    "    df.to_csv(path, encoding='utf-8', mode='a', header=True, index=False)\n",
    "\n",
    "#Run function to export\n",
    "df2csv(model_df, 'Model/model')\n",
    "print('Creating file: model_voterdata.csv --> COMPLETED')\n",
    "df2csv(blind_df, 'Blind/blind')\n",
    "print('Creating file: blind_voterdata.csv --> COMPLETED')\n",
    "\n",
    "# Sending gzip files to trash\n",
    "send2trash.send2trash('VoterData/voterfile1.txt')\n",
    "send2trash.send2trash('VoterData/voterfile2.txt')\n",
    "send2trash.send2trash('VoterData/voterfile3.txt')\n",
    "send2trash.send2trash('VoterData/voterfile4.txt')\n",
    "print('Sending GZip files to local trash folder --> COMPLETED')\n",
    "\n",
    "dir_list = os.listdir('VoterData/')  \n",
    "print('\\n---- Files in directory:\\n', dir_list)\n",
    "\n",
    "print('\\n\\nExport & Save --> COMPLETED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
