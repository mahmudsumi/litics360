{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Litics360 Prototype Version Pv1.0\n",
    "# Partitioning and Splitting Voter Registration Database (OHIO)\n",
    "\n",
    "### Purpose:\n",
    "#1. Extract voters with declared PARTY_AFFLIIATION\n",
    "#2. Partition declared voters dataset into two -- Blind data for final testing and data for building model\n",
    "#3. Split MODEL data for building into two sets -- Pre and post\n",
    "#4. Split PRE for building into two sets -- Cleaning and for Training\n",
    "#5. Split POST into two sets -- Cross Validation and for testing\n",
    "#6. Export separately.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import file1\n",
    "voterdata_file1 = pd.read_csv(\n",
    "    \"data/VoterData/sourced/SWVF_1_22.txt\", \n",
    "    sep=\",\", quotechar='\"', header=0, encoding='ISO-8859-1', na_values=['NA'],low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import file2\n",
    "voterdata_file2 = pd.read_csv(\n",
    "    \"data/VoterData/sourced/SWVF_23_44.txt\", \n",
    "    sep=\",\", quotechar='\"', header=0, encoding='ISO-8859-1', na_values=['NA'],low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import file3\n",
    "voterdata_file3 = pd.read_csv(\n",
    "    \"data/VoterData/sourced/SWVF_45_66.txt\", \n",
    "    sep=\",\", quotechar='\"', header=0, encoding='ISO-8859-1', na_values=['NA'],low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import file4\n",
    "voterdata_file4 = pd.read_csv(\n",
    "    \"data/VoterData/sourced/SWVF_67_88.txt\", \n",
    "    sep=\",\", quotechar='\"', header=0, encoding='ISO-8859-1', na_values=['NA'],low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all into one dataframe\n",
    "voterdata_df = pd.concat([voterdata_file1,voterdata_file2,voterdata_file3,voterdata_file4], \n",
    "                         axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    "                         keys=None, levels=None, names=None, verify_integrity=False, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# #1: Extract Voters with Declared Party Affliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Registered Voters:  7700810\n",
      "\n",
      "Party Affiliations Listed Types:  [nan 'D' 'R' 'G' 'L']\n",
      "--> nan = Undeclared\n",
      "--> D = Democrat\n",
      "--> R = Republican\n",
      "--> G = Green\n",
      "--> L = Libertarian\n",
      "\n",
      "# of Undeclared Party Affiliation:  4459592\n",
      "# of Declared Party Affiliation:  3241218\n"
     ]
    }
   ],
   "source": [
    "#Number of voters\n",
    "print(\"# of Registered Voters: \", len(voterdata_df))\n",
    "\n",
    "#Unique types of party affiliations listed in dataset\n",
    "parties = voterdata_df.PARTY_AFFILIATION.unique()\n",
    "print(\"\\nParty Affiliations Listed Types: \", parties)\n",
    "print(\"--> nan = Undeclared\\n--> D = Democrat\\n--> R = Republican\\n--> G = Green\\n--> L = Libertarian\")\n",
    "\n",
    "#Number of undeclared/declared voters\n",
    "num_undeclaredvoters = sum(pd.isna(voterdata_df['PARTY_AFFILIATION']))\n",
    "print(\"\\n# of Undeclared Party Affiliation: \", num_undeclaredvoters)\n",
    "\n",
    "num_declaredvoters = len(voterdata_df)-(sum(pd.isna(voterdata_df['PARTY_AFFILIATION'])))\n",
    "print(\"# of Declared Party Affiliation: \", num_declaredvoters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match #declared-voters to #rows of df:\n",
      " 3241218 <--> 3241218\n"
     ]
    }
   ],
   "source": [
    "#Extract all voters with declared party into dataset\n",
    "df = voterdata_df[pd.notnull(voterdata_df['PARTY_AFFILIATION'])]\n",
    "\n",
    "#Check number of rows -- match  to above\n",
    "print(\"Match #declared-voters to #rows of df:\\n\", num_declaredvoters,\"<-->\",len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# #2. Partition Dataset: Blind Data and Model Data\n",
    "1. BLIND - 10%\n",
    "2. MODEL - 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total declared voters:  3241218\n",
      "\n",
      "10% of 3241218 = 324122 \n",
      " BLIND dataset = 324122\n",
      "\n",
      "90% of 3241218 = 2917096 \n",
      " MODEL dataset = 2917096\n"
     ]
    }
   ],
   "source": [
    "#Partition into blind and model - 10/90, random_state none, shuffle True, \n",
    "model_df, blind_df= split(\n",
    "    df, train_size=0.9, test_size=0.1, random_state=None, shuffle=True)\n",
    "\n",
    "#Total declared voter count\n",
    "print(\"Total declared voters: \", len(df))\n",
    "\n",
    "#Calculate percentage, check # of rows in BLIND df\n",
    "print(\"\\n10% of\", len(df) ,\"=\",round(0.1*3241218),\"\\n BLIND dataset =\",len(blind_df))\n",
    "\n",
    "#Calculate percentage, check # of rows in MODEL df\n",
    "print(\"\\n90% of\", len(df) ,\"=\",round(0.9*3241218),\"\\n MODEL dataset =\",len(model_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# #3. Split Model Dataset: Prep and Test\n",
    "1. PRE - 60%\n",
    "3. POST - 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total in Model dataset:  2917096\n",
      "\n",
      "60% of 2917096 = 1750258 \n",
      " PRE dataset = 1750257\n",
      "\n",
      "40% of 2917096 = 1166838 \n",
      " POST dataset = 1166839\n"
     ]
    }
   ],
   "source": [
    "#Split MODEL dataset into prep and test - 60/40, shuffle, random state none\n",
    "pre_df, post_df= split(\n",
    "    model_df, test_size=0.4, train_size=0.6, random_state=None, shuffle=True)\n",
    "\n",
    "#Total declared voter count\n",
    "print(\"Total in Model dataset: \", len(model_df))\n",
    "\n",
    "#Calculate percentage, check # of rows in PREP df\n",
    "print(\"\\n60% of\", len(model_df) ,\"=\",round(0.6*2917096),\"\\n PRE dataset =\",len(pre_df))\n",
    "\n",
    "#Calculate percentage, check # of rows in TEST df\n",
    "print(\"\\n40% of\", len(model_df) ,\"=\",round(0.4*2917096),\"\\n POST dataset =\",len(post_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# #4. Split Pre Dataset: Exploration and Training\n",
    "1. EXPLORE_CLEAN - 5% \n",
    "2. TRAIN - 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total in PRE dataset:  1750257\n",
      "\n",
      "5% of 1750257 = 87513 \n",
      " EXPLORE_CLEAN dataset = 87513\n",
      "\n",
      "95% of 1750257 = 1662744 \n",
      " TRAIN dataset = 1662744\n"
     ]
    }
   ],
   "source": [
    "#Split PRE dataset into explore and train - 5/95, shuffle, random state none\n",
    "train_df, explore_clean_df= split(\n",
    "    pre_df, test_size=0.05, train_size=0.95, random_state=None, shuffle=True)\n",
    "\n",
    "#Total declared voter count\n",
    "print(\"Total in PRE dataset: \", len(pre_df))\n",
    "\n",
    "#Calculate percentage, check # of rows in EXPLORE df\n",
    "print(\"\\n5% of\", len(pre_df) ,\"=\",round(0.05*1750257),\"\\n EXPLORE_CLEAN dataset =\",len(explore_clean_df))\n",
    "\n",
    "#Calculate percentage, check # of rows in TRAIN df\n",
    "print(\"\\n95% of\", len(pre_df) ,\"=\",round(0.95*1750257),\"\\n TRAIN dataset =\",len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# #5. Split Post Dataset: Cross-Validation and Testing\n",
    "1. VALIDATE - 50% \n",
    "2. TEST - 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total in POST dataset:  1166839\n",
      "\n",
      "50% of 1166839 = 583420 \n",
      " VALIDATE dataset = 583419\n",
      "\n",
      "50% of 1166839 = 583420 \n",
      " TEST dataset = 583420\n"
     ]
    }
   ],
   "source": [
    "#Split POST dataset into explore and train - 50/50, shuffle, random state none\n",
    "validate_df, test_df= split(\n",
    "    post_df, test_size=0.5, train_size=0.5, random_state=None, shuffle=True)\n",
    "\n",
    "#Total declared voter count\n",
    "print(\"Total in POST dataset: \", len(post_df))\n",
    "\n",
    "#Calculate percentage, check # of rows in VALIDATE df\n",
    "print(\"\\n50% of\", len(post_df) ,\"=\",round(0.5*1166839),\"\\n VALIDATE dataset =\",len(validate_df))\n",
    "\n",
    "#Calculate percentage, check # of rows in TEST df\n",
    "print(\"\\n50% of\", len(post_df) ,\"=\",round(0.5*1166839),\"\\n TEST dataset =\",len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "# #6. Export 5 datasets -- Blind, explore/clean, train, validate, test\n",
    "\n",
    "### Research and Explore Data\n",
    "1. explore_clean_df --> data/VoterData/split/explore_clean_RAW_voterdata.csv\n",
    "\n",
    "### Train/Cross-Validation\n",
    "2. train_df --> data/VoterData/split/train_RAW_voterdata.csv\n",
    "3. validate_df --> data/VoterData/split/validate_RAW_voterdata.csv\n",
    "\n",
    "### Test\n",
    "4. test_df --> data/VoterData/split/test_RAW_voterdata.csv\n",
    "5. blind_df --> data/VoterData/blind/blind_RAW_voterdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for easy export to csv\n",
    "def df2csv(df,filename):\n",
    "    path = 'data/VoterData/'+filename+'_RAW_voterdata.csv'\n",
    "    df.to_csv(path, encoding='utf-8', mode='a', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run function to export\n",
    "df2csv(explore_clean_df, 'explore_clean/explore_clean')\n",
    "df2csv(train_df, 'train/train')\n",
    "df2csv(test_df, 'valid_test/test')\n",
    "df2csv(validate_df, 'valid_test/validate')\n",
    "df2csv(blind_df, 'blind/blind')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
